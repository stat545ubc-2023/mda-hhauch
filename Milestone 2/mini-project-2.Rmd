---
title: "Mini Data Analysis Milestone 2"
output: github_document
---

*To complete this milestone, you can either edit [this `.rmd` file](https://raw.githubusercontent.com/UBC-STAT/stat545.stat.ubc.ca/master/content/mini-project/mini-project-2.Rmd) directly. Fill in the sections that are commented out with `<!--- start your work here--->`. When you are done, make sure to knit to an `.md` file by changing the output in the YAML header to `github_document`, before submitting a tagged release on canvas.*

# Welcome to the rest of your mini data analysis project!

In Milestone 1, you explored your data. and came up with research questions. This time, we will finish up our mini data analysis and obtain results for your data by: 

- Making summary tables and graphs 
- Manipulating special data types in R: factors and/or dates and times.
-   Fitting a model object to your data, and extract a result.
-   Reading and writing data as separate files.

We will also explore more in depth the concept of *tidy data.* 

**NOTE**: The main purpose of the mini data analysis is to integrate what you learn in class in an analysis. Although each milestone provides a framework for you to conduct your analysis, it's possible that you might find the instructions too rigid for your data set. If this is the case, you may deviate from the instructions -- just make sure you're demonstrating a wide range of tools and techniques taught in this class.

# Instructions

**To complete this milestone**, edit [this very `.Rmd` file](https://raw.githubusercontent.com/UBC-STAT/stat545.stat.ubc.ca/master/content/mini-project/mini-project-2.Rmd) directly. Fill in the sections that are tagged with `<!--- start your work here--->`.

**To submit this milestone**, make sure to knit this `.Rmd` file to an `.md` file by changing the YAML output settings from `output: html_document` to `output: github_document`. Commit and push all of your work to your mini-analysis GitHub repository, and tag a release on GitHub. Then, submit a link to your tagged release on canvas.

**Points**: This milestone is worth 50 points: 45 for your analysis, and 5 for overall reproducibility, cleanliness, and coherence of the Github submission. 

**Research Questions**: In Milestone 1, you chose two research questions to focus on. Wherever realistic, your work in this milestone should relate to these research questions whenever we ask for justification behind your work. In the case that some tasks in this milestone don't align well with one of your research questions, feel free to discuss your results in the context of a different research question.

# Learning Objectives

By the end of this milestone, you should:

-   Understand what *tidy* data is, and how to create it using `tidyr`.
-   Generate a reproducible and clear report using R Markdown.
-   Manipulating special data types in R: factors and/or dates and times.
-   Fitting a model object to your data, and extract a result.
-   Reading and writing data as separate files.

# Setup

Begin by loading your data and the tidyverse package below:

```{r, message = FALSE}
library(datateachr) # <- might contain the data you picked!
library(tidyverse) 
library(dplyr)
```

# Task 1: Process and summarize your data 

From milestone 1, you should have an idea of the basic structure of your dataset (e.g. number of rows and columns, class types, etc.). Here, we will start investigating your data more in-depth using various data manipulation functions. 

### 1.1 (1 point) 

First, write out the 4 research questions you defined in milestone 1 were. This will guide your work through milestone 2:

<!-------------------------- Start your work below ---------------------------->
1. What is the relationship between the size of cells and diagnosis?
2. What is the relationship between the texture/smoothness of the cell and diagnosis?
3. What is the relationship between the symmetry of the cell and diagnosis?
4. What is the relationship between the concavity of the cell and diagnosis?
<!----------------------------------------------------------------------------->

Here, we will investigate your data using various data manipulation and graphing functions.

### 1.2 (8 points)

Now, for each of your four research questions, choose one task from options 1-4 (summarizing), and one other task from 4-8 (graphing). You should have 2 tasks done for each research question (8 total). Make sure it makes sense to do them! (e.g. don't use a numerical variables for a task that needs a categorical variable.). Comment on why each task helps (or doesn't!) answer the corresponding research question.

Ensure that the output of each operation is printed!

Also make sure that you're using dplyr and ggplot2 rather than base R. Outside of this project, you may find that you prefer using base R functions for certain tasks, and that's just fine! But part of this project is for you to practice the tools we learned in class, which is dplyr and ggplot2.

**Summarizing:**

1.  Compute the *range*, *mean*, and *two other summary statistics* of **one numerical variable** across the groups of **one categorical variable** from your data. 
2.  Compute the number of observations for at least one of your categorical variables. Do not use the function `table()`! =
3.  Create a categorical variable with 3 or more groups from an existing numerical variable. You can use this new variable in the other tasks! *An example: age in years into "child, teen, adult, senior".* 
4. Compute the proportion and counts in each category of one categorical variable across the groups of another categorical variable from your data. Do not use the function `table()`!

**Graphing:**

6. Create a graph of your choosing, make one of the axes logarithmic, and format the axes labels so that they are "pretty" or easier to read. 

7. Make a graph where it makes sense to customize the alpha transparency. 

Using variables and/or tables you made in one of the "Summarizing" tasks: 

8. Create a graph that has at least two geom layers. 
9. Create 3 histograms, with each histogram having different sized bins. Pick the "best" one and explain why it is the best.

Make sure it's clear what research question you are doing each operation for!

<!------------------------- Start your work below ----------------------------->
### 1. What is the relationship between the size of cells and diagnosis?
#### Summarizing: 3
This task allows us to categorize the different sizes of the nuclei into categories. This will allow us to better visualize the data to see if there is a correlation between the size (small vs. large) and the diagnosis. The sizes were chosen based off of the mean, first quartile, and third quartile of the benign cells which were identified using the summary function on the area_mean for both metastatic and benign patients. 

```{r}
area_mean_levels <- cancer_sample %>% #creating a new variable 
mutate(area_mean_level = case_when (area_mean < 378 ~"very small", #within the new variable creating new column that coincide with my chosen boundaries
                              area_mean < 462 ~ "small",
                              area_mean < 551 ~ "large",
                              TRUE ~ "very large"))%>%
select(diagnosis, area_mean, area_mean_level) #selecting for only the relevant columns 

print(area_mean_levels) #showing the tibble
```

### Graphing: 8
This graphing task allows us to visualize the difference in the mean area of the nucleus between cells and between diagnosis's. The jitter plot allows us to see the difference between metastatic and benign with the box plot aiding in identifying the difference as well as the larger range in sizes we see for metastatic. Using the newly made categorically variable we can see that although the mean for the M diagnosis is higher than for B cells we can see that most of the cells for metastatic patients can be categorized as "very large". 

```{r}
R1_graph <- area_mean_levels %>% #creating new variable 
ggplot(aes(diagnosis, area_mean))+ 
geom_jitter(alpha = 0.5, aes(color = area_mean_level)) + #choosing a jitter plot and assigning the colors to the different sizes of nuclei area
geom_boxplot(alpha = 0) + #adding clear boxplot so it doesn't block points 
  ylab("Mean Area of Nuclei") + #changing y axis label to a clearer title
  ggtitle("Mean Area of Nuclei For Benign and Metastatic Cells")+ #adding a title
  theme(legend.title = element_blank()) #I though the legend title was not helpful so I removed it

print(R1_graph)


```

### 2. What is the relationship between the texture/smoothness of the cell and diagnosis?
#### Summarizing: 1
In this task I computed the range, mean, median, standard deviation (sd), and IQR for both texture and smoothness of the nuclei against the diagnosis categorical variable. Although the task asks to compute for one numerical variable for this question it makes sense to apply to both texture and smoothness. This tasks shows us the overall differences in the numerical values for both metastatic and benign patients. For mean_texture, we can see that for metastatic cases the mean, median, max, and min texture is higher than for benign cases. We can also see that the IQR and sd are relatively close showing that the variance from the mean in both data sets are similar. Interestingly for mean_smoothness the max_smoothness is higher for benign cells. 

```{r}
summarize_cancer_texture <- cancer_sample %>%
group_by(diagnosis) %>% #grouping by diagnosis to compare data between benign and metastatic
  summarize(mean_texture = mean(texture_mean, na.rm = TRUE), #creates new data fram and finding mean
  median_texture = median(texture_mean, na.rm = TRUE), #finding median
  max_texture = max(texture_mean, na.rm = TRUE), #finding max
  min_texture = min(texture_mean, na.rm = TRUE), #finding min
  IRQ_texture = IQR(texture_mean, na.rm = TRUE), #finding IDR
  sd_texture = sd(texture_mean, na.rm = TRUE)) #finding sd 

head(summarize_cancer_texture)

summarize_cancer_smoothness <- cancer_sample %>%
group_by(diagnosis) %>% #grouping by diagnosis to compare data between benign and metastatic
  summarize(mean_smoothness = mean(smoothness_mean, na.rm = TRUE), #creates new data fram and finding mean
  median_smoothness = median(smoothness_mean, na.rm = TRUE), #finding median
  max_smoothness = max(smoothness_mean, na.rm = TRUE),#finding max
  min_smoothness = min(smoothness_mean, na.rm = TRUE),#finding min
  IRQ_smoothness = IQR(smoothness_mean, na.rm = TRUE),#finding IDR
  sd_smoothness = sd(smoothness_mean, na.rm = TRUE))#finding sd 

head(summarize_cancer_smoothness)
```


#### Graphing: 6
This task allows us to produce a graph that looks at the relationship between cell nuclei smoothness and cell nuclei texture. We can see that the mean smoothness is similar between diagnosis with metastatic cells having slightly higher value. However, for mean texture of the nuclei it is clear that benign cells seem to have a lower mean texture than metastatic cells. Adding the labels and log scale makes the graph much easier to read and prevents data points for blocking each other. 

```{r}
R2_graph <- cancer_sample %>% 
  ggplot(aes(texture_mean, smoothness_mean)) + #choosing graph variables
  geom_point(alpha = 0.3, aes(color = diagnosis))+ #using scatter plot and adjusting alpha so points are more transparent. The color coincides with the diagnosis to show the difference
  theme_minimal()+ 
  scale_x_log10("Mean Texture of Cell")+ #making the x axis log scale and adding axis title
  scale_y_log10("Mean Smoothness of Cell") + #making the y axis log scale and adding axis title
  ggtitle("Mean Texture and Mean Smoothness of Nuclei for Benign and Metastatic Cells ") #adding title 

print(R2_graph)
```

  
### 3. What is the relationship between the symmetry of the cell and diagnosis?
#### Summarizing: 1
In this task I computed the range, mean, median, standard deviation (sd), and IQR for the symmetry of the nuclei against the diagnosis categorical variable. This tasks shows up the overall differences in the numerical values for both metastatic and benign patients. For mean_symmetry, we can see that for metastatic cases the mean, median, max, and min texture is slightly higher than for benign cases. We can also see that the IQR and sd are relatively close showing that the variance from the mean in both data sets are similar. 

```{r}
summarize_cancer_symmetry <- cancer_sample %>%
group_by(diagnosis) %>% #grouping by diagnosis to compare data between benign and metastatic
  summarize(mean_symmetry = mean(symmetry_mean, na.rm = TRUE), #creates new data fram and finding mean
  median_symmetry = median(symmetry_mean, na.rm = TRUE), #median
  max_symmetry = max(symmetry_mean, na.rm = TRUE), #max
  min_symmetry = min(symmetry_mean, na.rm = TRUE), #min
  IRQ_symmetry = IQR(symmetry_mean, na.rm = TRUE), #IQR
  sd_symmetry = sd(symmetry_mean, na.rm = TRUE)) #sd

head(summarize_cancer_symmetry)
```

#### Graphing: 7
This task where we customize the alpha transparency which allows us to visualize the points that are overlapping with others. This plot allows us to visualize the difference in symmetry between the nuclei from benign and metastatic cells. As you can see, the mean symmetry is higher in metastatic cells. 

```{r}
R3_graph <- cancer_sample %>% #choosing the data set
  ggplot(aes(diagnosis, symmetry_mean)) + #I selected to compare diagnosis with symmetry mean
  geom_jitter(alpha = 0.5, aes(color = diagnosis))+ #I used a jitter blot as it would allow us to visualize the relationship symmetry mean has with both diagnosises and also compare the diagnoses to each other 
  theme_minimal()+ 
  geom_boxplot(aes(color = diagnosis), alpha = 0)+ #made the colors of the box plot correspond with the side they were on bby diagnosis and made them transparent so they wouldn't block data 
  ylab("Mean Symmetry of Nuclei") + #adding y axis label
  ggtitle("Mean Symmetry of Nuclei For Benign and Metastatic Cells")+ #adding title
  theme(legend.position="none") #don't think the legend adds any new information that isn't already shwon by the axis 


print(R3_graph)
```
  
### 4. What is the relationship between the concavity of the cell and diagnosis?
In this task I computed the range, mean, median, standard deviation (sd), and IQR for the concavity of the nuclei against the diagnosis categorical variable. This tasks shows up the overall differences in the numerical values for both metastatic and benign patients. For mean_concavity, we can see that for metastatic cases the mean, median and min texture is higher than for benign cases. The max convacity is only slightly higher for metastatic cells. We can also see that the IQR and sd are slighly different with the metastatic data having a higher IQR and sd.

```{r}
summarize_cancer_concavity <- cancer_sample %>%
group_by(diagnosis) %>% #grouping by diagnosis to compare data between benign and metastatic
  summarize(Mean_concavity = mean(concavity_mean, na.rm = TRUE), #creates new data fram and finding mean
  median_concavity = median(concavity_mean, na.rm = TRUE), #median
  max_concavity = max(concavity_mean, na.rm = TRUE), #max
  min_concavity = min(concavity_mean, na.rm = TRUE), #min
  IRQ_concavity = IQR(concavity_mean, na.rm = TRUE), #IQR
  sd_concavity = sd(concavity_mean, na.rm = TRUE)) #sd

head(summarize_cancer_concavity)
```


#### Graphing: 7

This task where we customize the alpha transparency which allows us to visualize the points that are overlapping with others. This plot allows us to visualize the difference in concavity between the nuclei from benign and metastatic cells. As you can see, the mean concavity is higher in metastatic cells, however there are a few cells in the benign diagnosis that have high mean concavity. 

```{r}
R4_graph <- cancer_sample %>% #choosing the data set
  ggplot(aes(diagnosis, concavity_mean)) + #I selected to compare diagnosis with concavity mean
  geom_jitter(alpha = 0.5, aes(color = diagnosis))+ #I used a jitter blot as it would allow us to #visualize the relationship radius mean has with both diagnosises and also compare the diagnoses to each #other 
  theme_minimal()+ 
  geom_boxplot(aes(color = diagnosis), alpha = 0)+ #made the colors of the box plot correspond with the side they were on bby diagnosis and made them transparent so they wouldn't block data 
  ylab("Mean Concavity of Nuclei") + #y axis label 
  ggtitle("Mean Convavity of Nuclei For Benign and Metastatic Cells") + #title
  theme(legend.position="none") #don't think the legend adds any new information that isn't already shwon by the axis 

print(R4_graph)
```

<!----------------------------------------------------------------------------->

### 1.3 (2 points)

Based on the operations that you've completed, how much closer are you to answering your research questions? Think about what aspects of your research questions remain unclear. Can your research questions be refined, now that you've investigated your data a bit more? Which research questions are yielding interesting results?

<!------------------------- Write your answer here ---------------------------->
### Reflecting on task 1
Based on the summarizing and graphing activities I am closer to answering the research questions. In the summarizing results for all questions we can see that there is a difference in these nuclei attributes between patients with metastatic cancer and benign cancer. We can visualize this differences in the graphs produced. For example, for patients with metastatic cancer the average nucleus size is larger with a bigger proportion of cells falling within the "very large" size category. For texture/smoothness of the nucleus we see that there is a divide between the two with benign cell nuclei having on average lower mean texture and mean smoothness. We also see differences with concavity and symmetry of the cells nuclei. The aspects of the research questions that remain unclear are if these differences of statistically significant. To refine the questions I think we could look further into the statistically significant attributes. So far I think all the questions have yielded interesting results. I think the ones that are most apparent are the area of the nuclei and the concavity of the nuclei. 

<!----------------------------------------------------------------------------->

# Task 2: Tidy your data 

In this task, we will do several exercises to reshape our data. The goal here is to understand how to do this reshaping with the `tidyr` package.

A reminder of the definition of *tidy* data:

-   Each row is an **observation**
-   Each column is a **variable**
-   Each cell is a **value**

### 2.1 (2 points)

Based on the definition above, can you identify if your data is tidy or untidy? Go through all your columns, or if you have \>8 variables, just pick 8, and explain whether the data is untidy or tidy.

<!--------------------------- Start your work below --------------------------->

Based on the definition above my data is tidy. For example, the first 8 variables: ID, diagnosis, radius_mean, texture_mean, perimeter_mean, area_mean, smoothness_mean, and compactness_mean, are all a different variables either about the patients or the cells they observed. Each row for all these columns look at the mean of an attribute of the cell, which would have been observed and then calculated. Each cell within the rows contains a value of some kind either it be the mean of an attribute or the patients ID number. 

<!----------------------------------------------------------------------------->

### 2.2 (4 points)

Now, if your data is tidy, untidy it! Then, tidy it back to it's original state.

If your data is untidy, then tidy it! Then, untidy it back to it's original state.

Be sure to explain your reasoning for this task. Show us the "before" and "after".

<!--------------------------- Start your work below --------------------------->

As mentioned above the originally data is tidy. To untidy it I made the tibble 'longer' by putting the different variables from the columns (e.g. area_mean, radius_mean, texture_mean, etc.) into a single column titled _name_. The value of the variables are then put into column called _value_. This makes the data much harder to use and more complicated. To retidy it to its original state I made the tibble 'wider' and made new variables with the name of the variables from the _name_ column and the values of the new variables from the _value_ column. 

```{r}
untidy_cancer_sample <- cancer_sample %>%
pivot_longer(-c(ID, diagnosis))

print(untidy_cancer_sample)

tidy_cancer_sample <- untidy_cancer_sample %>%
pivot_wider(names_from = name, values_from = value)

print(tidy_cancer_sample)
```


<!----------------------------------------------------------------------------->

### 2.3 (4 points)

Now, you should be more familiar with your data, and also have made progress in answering your research questions. Based on your interest, and your analyses, pick 2 of the 4 research questions to continue your analysis in the remaining tasks:

<!-------------------------- Start your work below ---------------------------->

1.  What is the relationship between the size of cells and diagnosis?
2.  What is the relationship between the symmetry of the cell and diagnosis?

<!----------------------------------------------------------------------------->

Explain your decision for choosing the above two research questions.
<!--------------------------- Start your work below --------------------------->
I chose the above two research questions because the size of the cell and diagnosis seems to have a clearer relationship based on the analysis so far. From what we have seen I think that the larger the size of the nuclei the more likely it is that the cancer is metastatic. However, for symmetry that relationship is less clear. Therefore, for the following tasks where we can run a hypothesis test I would like to see if there is significance in the data. 
<!----------------------------------------------------------------------------->

Now, try to choose a version of your data that you think will be appropriate to answer these 2 questions. Use between 4 and 8 functions that we've covered so far (i.e. by filtering, cleaning, tidy'ing, dropping irrelevant columns, etc.).

(If it makes more sense, then you can make/pick two versions of your data, one for each research question.) 

<!--------------------------- Start your work below --------------------------->

```{r}
task_3_version_area_symmetry <- cancer_sample %>% #creating new variable and choosing data set
filter(is.numeric(c(area_mean,symmetry_mean))) %>% #filter for only numeric values
select(c(diagnosis, area_mean, symmetry_mean)) %>% #selecting our variables of intrest
mutate(area_mean_level = case_when (area_mean < 378 ~"very small", #creating a new coloum related to the size of the cell 
                              area_mean < 462 ~ "small",
                              area_mean < 551 ~ "large",
                              TRUE ~ "very large")) %>%
relocate("diagnosis", "symmetry_mean", "area_mean", "area_mean_level") #rearranging the tibble so it is clear 

                              
head(task_3_version_area_symmetry)
```

# Task 3: Modelling

## 3.0 (no points)

Pick a research question from 1.2, and pick a variable of interest (we'll call it "Y") that's relevant to the research question. Indicate these.

<!-------------------------- Start your work below ---------------------------->

**Research Question**: What is the relationship between the cell nuclei symmetry and diagnosis?

**Variable of interest**: symmetry

<!----------------------------------------------------------------------------->

## 3.1 (3 points)

Fit a model or run a hypothesis test that provides insight on this variable with respect to the research question. Store the model object as a variable, and print its output to screen. We'll omit having to justify your choice, because we don't expect you to know about model specifics in STAT 545.

-   **Note**: It's OK if you don't know how these models/tests work. Here are some examples of things you can do here, but the sky's the limit.

    -   You could fit a model that makes predictions on Y using another variable, by using the `lm()` function.
    -   You could test whether the mean of Y equals 0 using `t.test()`, or maybe the mean across two groups are different using `t.test()`, or maybe the mean across multiple groups are different using `anova()` (you may have to pivot your data for the latter two).
    -   You could use `lm()` to test for significance of regression coefficients.

<!-------------------------- Start your work below ---------------------------->

```{r}
symmetry_mean_model <- t.test(symmetry_mean ~ diagnosis, data = task_3_version_area_symmetry) #t-test on the symmetry_mean based on the diagnosis taking the data from the tibble from task 2.3

print(symmetry_mean_model)
```


<!----------------------------------------------------------------------------->

## 3.2 (3 points)

Produce something relevant from your fitted model: either predictions on Y, or a single value like a regression coefficient or a p-value.

-   Be sure to indicate in writing what you chose to produce.
-   Your code should either output a tibble (in which case you should indicate the column that contains the thing you're looking for), or the thing you're looking for itself.
-   Obtain your results using the `broom` package if possible. If your model is not compatible with the broom function you're needing, then you can obtain your results by some other means, but first indicate which broom function is not compatible.

<!-------------------------- Start your work below ---------------------------->
### Fitted Model 
I choose to run a t-test to determine the p-value of the data to see if the data is statistically significant. Based on the t-test we can reject the null hypothesis and say that the data is statistially significant. 
```{r}
library(broom) #loading broom package 
```


```{r}
symmetry_mean_model <- t.test(symmetry_mean ~ diagnosis, data = task_3_version_area_symmetry) #t-test

tidy(symmetry_mean_model) #put t-test in tibble using broom package

print(symmetry_mean_model)


```

<!----------------------------------------------------------------------------->

# Task 4: Reading and writing data

Get set up for this exercise by making a folder called `output` in the top level of your project folder / repository. You'll be saving things there.

## 4.1 (3 points)

Take a summary table that you made from Task 1, and write it as a csv file in your `output` folder. Use the `here::here()` function.

-   **Robustness criteria**: You should be able to move your Mini Project repository / project folder to some other location on your computer, or move this very Rmd file to another location within your project repository / folder, and your code should still work.
-   **Reproducibility criteria**: You should be able to delete the csv file, and remake it simply by knitting this Rmd file.

<!-------------------------- Start your work below ---------------------------->

```{r}
library(here) #loading here package

```

```{r}
area_mean_levels <- cancer_sample %>%
mutate(area_mean_level = case_when (area_mean < 378 ~"very small",
                              area_mean < 462 ~ "small",
                              area_mean < 551 ~ "large",
                              TRUE ~ "very large"))
select(area_mean_levels, diagnosis, area_mean, area_mean_level) 

write_csv(area_mean_levels, here("Output", "area_mean_levels.csv")) #writing csv and putting it into output folder
```


<!----------------------------------------------------------------------------->

## 4.2 (3 points)

Write your model object from Task 3 to an R binary file (an RDS), and load it again. Be sure to save the binary file in your `output` folder. Use the functions `saveRDS()` and `readRDS()`.

-   The same robustness and reproducibility criteria as in 4.1 apply here.

<!-------------------------- Start your work below ---------------------------->
```{r}
saveRDS(symmetry_mean_model, here('Output', "area_mean_model.RDS")) #writing to a R binary file and saving in output folder

readRDS(here('Output', "area_mean_model.RDS")) #loading the RDS
```

<!----------------------------------------------------------------------------->

# Overall Reproducibility/Cleanliness/Coherence Checklist 

Here are the criteria we're looking for.

## Coherence (0.5 points)

The document should read sensibly from top to bottom, with no major continuity errors. 

The README file should still satisfy the criteria from the last milestone, i.e. it has been updated to match the changes to the repository made in this milestone. 

## File and folder structure (1 points)

You should have at least three folders in the top level of your repository: one for each milestone, and one output folder. If there are any other folders, these are explained in the main README.

Each milestone document is contained in its respective folder, and nowhere else.

Every level-1 folder (that is, the ones stored in the top level, like "Milestone1" and "output") has a `README` file, explaining in a sentence or two what is in the folder, in plain language (it's enough to say something like "This folder contains the source for Milestone 1").

## Output (1 point)

All output is recent and relevant:

-   All Rmd files have been `knit`ted to their output md files. 
-   All knitted md files are viewable without errors on Github. Examples of errors: Missing plots, "Sorry about that, but we can't show files that are this big right now" messages, error messages from broken R code
-   All of these output files are up-to-date -- that is, they haven't fallen behind after the source (Rmd) files have been updated.
-   There should be no relic output files. For example, if you were knitting an Rmd to html, but then changed the output to be only a markdown file, then the html file is a relic and should be deleted.

Our recommendation: delete all output files, and re-knit each milestone's Rmd file, so that everything is up to date and relevant.

## Tagged release (0.5 point)

You've tagged a release for Milestone 2. 

### Attribution

Thanks to Victor Yuan for mostly putting this together.
